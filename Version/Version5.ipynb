{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Specialized ML models\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.callbacks import Callback\n",
    "\n",
    "# Deep learning\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Utility\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install /kaggle/input/tabnet/pytorch/v1/1/pytorch_tabnet-4.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_data_parquet(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    stats, indexes = zip(*results)\n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "          'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "          'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "train_ts = load_data_parquet(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_data_parquet(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "train = train[featuresCols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan_values(data):\n",
    "    imputer = KNNImputer(n_neighbors=71)\n",
    "    numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    imputed_data = imputer.fit_transform(data[numeric_cols])\n",
    "    data_imputed = pd.DataFrame(imputed_data, columns=numeric_cols)\n",
    "    \n",
    "    if 'sii' in data.columns:\n",
    "        data_imputed['sii'] = data_imputed['sii'].round().astype(int)\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if col not in numeric_cols:\n",
    "            data_imputed[col] = data[col]\n",
    "    \n",
    "    return data_imputed\n",
    "\n",
    "def handle_category_data(data):\n",
    "    all_categories = ['Spring', 'Summer', 'Fall', 'Winter']\n",
    "    df_encoded = data.copy()\n",
    "    encoder = OneHotEncoder(categories=[all_categories], sparse_output=False, handle_unknown='ignore', dtype=int)\n",
    "    \n",
    "    for column in data.select_dtypes(include=['object', 'category']).columns:\n",
    "        encoded_array = encoder.fit_transform(df_encoded[[column]])\n",
    "        encoded_columns = [f\"{column}_{season}\" for season in all_categories]\n",
    "        encoded_df = pd.DataFrame(encoded_array, columns=encoded_columns, index=data.index)\n",
    "        df_encoded = pd.concat([df_encoded.drop(column, axis=1), encoded_df], axis=1)\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "train = fill_nan_values(train)\n",
    "train = handle_category_data(train)\n",
    "test = fill_nan_values(test)\n",
    "test = handle_category_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Replace infinite values with NaN in the train dataset\n",
    "if np.any(np.isinf(train)):\n",
    "    train = train.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_rounder(oof_non_rounded, thresholds):\n",
    "    return np.digitize(oof_non_rounded, bins=thresholds, right=True)\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_predictions = threshold_rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from colorama import Fore, Style\n",
    "\n",
    "def train_model(model, test_data, train_data, sample, n_splits=5, seed=42):\n",
    "    X = train_data.drop(['sii'], axis=1)\n",
    "    y = train_data['sii']\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    \n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    \n",
    "    oof_predictions = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_predictions = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tqdm(skf.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model_instance = clone(model)\n",
    "        model_instance.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model_instance.predict(X_train)\n",
    "        y_val_pred = model_instance.predict(X_val)\n",
    "\n",
    "        oof_predictions[val_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[val_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_scores.append(train_kappa)\n",
    "        val_scores.append(val_kappa)\n",
    "        \n",
    "        test_predictions[:, fold] = model_instance.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_scores):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(val_scores):.4f}\")\n",
    "\n",
    "    kappa_optimizer = minimize(evaluate_predictions,\n",
    "                               x0=[0.5, 1.5, 2.5], args=(y, oof_predictions), \n",
    "                               method='Nelder-Mead')\n",
    "    assert kappa_optimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_rounder(oof_predictions, kappa_optimizer.x)\n",
    "    tuned_kappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tuned_kappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    test_predictions_mean = test_predictions.mean(axis=1)\n",
    "    test_predictions_tuned = threshold_rounder(test_predictions_mean, kappa_optimizer.x)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': test_predictions_tuned\n",
    "    })\n",
    "\n",
    "    return submission\n",
    "\n",
    "# Example usage:\n",
    "# SEED = 2004\n",
    "# n_splits = 5\n",
    "# model = VotingRegressor(estimators=[...])\n",
    "# submission = train_model(model, test, train, sample, n_splits=n_splits, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2004\n",
    "n_splits = 5\n",
    "# Model parameters for LightGBM\n",
    "Params = {\n",
    "    'learning_rate': 0.09970294901245966, \n",
    "    'max_depth': 3, \n",
    "    'subsample': 0.9651688449975022, \n",
    "    'colsample_bytree': 0.616732288405486, \n",
    "    'num_leaves': 34, \n",
    "    'min_data_in_leaf': 68, \n",
    "    'feature_fraction': 0.6476169754611282, \n",
    "    'bagging_fraction': 0.9184091064527949, \n",
    "    'bagging_freq': 10, \n",
    "    'reg_alpha': 0.015879148435808108, \n",
    "    'reg_lambda': 0.0036854044260839643\n",
    "}\n",
    "\n",
    "\n",
    "# XGBoost parameters\n",
    "XGB_Params = {\n",
    "    'learning_rate': 0.29682190417298865,\n",
    "    'max_depth': 4, 'n_estimators': 796,\n",
    "    'subsample': 0.7542484622989069,\n",
    "    'colsample_bytree': 0.886399359731497,\n",
    "    'reg_alpha': 0.014681067600657996,\n",
    "    'reg_lambda': 9.209859894025579,\n",
    "    'gamma': 0.06495942878096272, \n",
    "    'min_child_weight': 13,\n",
    "    'use_gpu': True\n",
    "}\n",
    "\n",
    "CatBoost_Params = {\n",
    "    'learning_rate': 0.026392650714515364, \n",
    "    'depth': 15, 'l2_leaf_reg': 0.0018692968691208557,\n",
    "    'iterations': 637, 'bagging_temperature': 0.45636037003578794,\n",
    "    'random_strength': 7.2357605130667455, 'border_count': 135, \n",
    "    'grow_policy': 'Lossguide'\n",
    "}\n",
    "Light = LGBMRegressor(**Params, random_state=SEED, verbose=-1, n_estimators=300)\n",
    "XGB_Model = XGBRegressor(**XGB_Params)\n",
    "CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingRegressor(estimators=[\n",
    "    ('lgb', Pipeline(steps=[ ('regressor', LGBMRegressor(random_state=SEED))])),\n",
    "    ('xgb', Pipeline(steps=[ ('regressor', XGBRegressor(random_state=SEED))])),\n",
    "    ('cat', Pipeline(steps=[ ('regressor', CatBoostRegressor(random_state=SEED, silent=True))])),\n",
    "    ('rf', Pipeline(steps=[('regressor', RandomForestRegressor(random_state=SEED))])),\n",
    "    ('gb', Pipeline(steps=[\n",
    "    ('regressor', GradientBoostingRegressor(random_state=SEED))\n",
    "]))\n",
    "])\n",
    "\n",
    "Submission3 = train_model(ensemble, test, train, sample, n_splits=n_splits, seed=SEED)\n",
    "Submission3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
